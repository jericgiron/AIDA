{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "fund_aiml_06v1_lec1_2021.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNyzEcWPusFYo9tAO6wyyhr",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dyjdlopez/AIDA/blob/main/activities/06%20-%20Neural%20Networks/fund_aiml_06v1_lec1_2021.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SsSAkmnxn_w9"
      },
      "source": [
        "# Topic 06.1: Neural Networks\n",
        "$_{\\text{©D.J. Lopez | 2021 | Fundamentals of Machine Learning}}$\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fNDOwbRtoUAD"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0-Ao7sdRn-iB"
      },
      "source": [
        "# !pip install tensorflow\n",
        "# !pip install tensorflow-gpu\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9n4IRnFPoc-q"
      },
      "source": [
        "## Part 1 Tensor Operations\n",
        "\n",
        "[TensorFlow](https://www.tensorflow.org/) is an end-to-end open source platform for machine learning. It has a comprehensive, flexible ecosystem of tools, libraries and community resources that lets researchers push the state-of-the-art in ML and developers easily build and deploy ML powered applications.<br>\n",
        "TensorFlow provides several APIs that allow developers to develop a range of AI Apps from data estimation, computer vision, natural language processing, and even reinforcement learning.\n",
        "![image](https://camo.githubusercontent.com/c04e16c05de80dadbdc990884672fc941fdcbbfbb02b31dd48c248d010861426/68747470733a2f2f7777772e74656e736f72666c6f772e6f72672f696d616765732f74665f6c6f676f5f736f6369616c2e706e67)<br>\n",
        "\n",
        "TensorFlow mainly operates using tensors (as its name suggests) so let’s try to use our current knowledge about tensors and apply it with our current platform."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sbvJb1mLokXq"
      },
      "source": [
        "### 1.1 NumPy and TensorFlow\n",
        "If you have enjoyed using matrices and tensors in NumPy, then performing tensor algebra in TensorFlow will just be a breeze."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x9JzpPE_oZ2b"
      },
      "source": [
        "np_tensor = np.array(3)\n",
        "tf_tensor = tf.constant(3)\n",
        "\n",
        "print(np_tensor)\n",
        "print(tf_tensor)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7ONYzsy_onCt"
      },
      "source": [
        "np_mat = np.array([\n",
        "                   [1,2],\n",
        "                   [3,1]\n",
        "], dtype=float)\n",
        "tf_mat = tf.constant([\n",
        "                      [1,2],\n",
        "                      [3,1]\n",
        "], dtype=float)\n",
        "print(np_mat)\n",
        "print(tf_mat)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BB8Sm56gootC"
      },
      "source": [
        "type(tf_mat.numpy())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "piMHuMBuop3L"
      },
      "source": [
        "A = tf_mat\n",
        "B = tf.transpose(tf_mat)\n",
        "print(f\"Matrix A: \\n{A}\")\n",
        "print(f\"Matrix B: \\n{B}\")\n",
        "print(f\"Sum of Tensors: \\n{A+B}\")\n",
        "print(f\"Difference of Tensors: \\n{A-B}\")\n",
        "print(f\"Product of Tensors: \\n{A*B}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "85hwd7IOorUz"
      },
      "source": [
        "print(f\"Dot Product of Tensors: \\n{A@B}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GJjJZYCgotf6"
      },
      "source": [
        "C = tf.reshape(A, [4,1])\n",
        "C"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "secLCryeoveq"
      },
      "source": [
        "## Part 2: Machine Learning Revisited\n",
        "As we recall, machine learning takes in data and a program to produce a rule or determine a pattern as opposed with traditional program that requires a pattern or rule together with the data to create a working system.\n",
        "\n",
        "Machine learning can be further classified into several cognitive paradigms:\n",
        "\n",
        "<b>Supervised learning</b>— is a type of machine learning that requires input data to have a feature and a label or the typical X data and y label format. Supervised learning requires its dataset to be:\n",
        "* Large (Volume)\n",
        "* Various\n",
        "* Valid\n",
        "\n",
        "<b>Unsupervised learning</b>—unlike input data from supervised learning, unsupervised learning data doesn't have labels. Unsupervised learning aims to find patterns in unexplored data. Typical applications of unsupervised learning include: dimension reduction and clustering.\n",
        "\n",
        "<b>Reinforcement learning</b>—the inputs for a reinforcement learning algorithm requires little to none data (in form of a dataset) to succeed in learning. Reinforcement learning aims to learn a rule, policy, or “way to do stuff” by determining whether its actions for a certain environment is rewarded or punished by its algorithm. The common uses of reinforcement learning included optimization.\n",
        "\n",
        "In the succeeding topics, we will be focusing on supervised learning using Deep Neural Networks."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TiY6dD7qpA-a"
      },
      "source": [
        "### 2.1 The Neuron (Again)\n",
        "![image](https://svitla.com/uploads/ckeditor/ArtificialNeuronModel_english.jpg)<br>\n",
        "\n",
        "Recalling our last discussion with the neuron, we found out that it is the basic unit of a neural network. The learning process of the neuron consists of a feed-forward propagation in which it takes in several inputs in which it is multiplied by some weights and fed into a transfer function and then subjected to an activation function; and a backward propagation routine where it computes for the loss and cost of a neuron and uses the error value to update the weights and repeating until it converges (or even diverge) to a certain period of training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BXtIyiIwovPE"
      },
      "source": [
        "#Features\n",
        "X = np.arange(-1,5,dtype=float)\n",
        "def fx(x): return 2*x-1\n",
        "#Targets/Labels\n",
        "y = np.array(list(map(fx,X)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R9gJYjB8pC_S"
      },
      "source": [
        "print(X)\n",
        "print(y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E4BOHTdEpDS5"
      },
      "source": [
        "from tensorflow.keras.optimizers import Adam, SGD, RMSprop\n",
        "from tensorflow.keras.losses import MSE, MAE"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TBU8W_VppDuZ"
      },
      "source": [
        "### Dense Layer\n",
        "model = tf.keras.Sequential([\n",
        "                             tf.keras.layers.Dense(units=1, input_shape=[1])\n",
        "])\n",
        "lr=0.01\n",
        "model.compile(optimizer=SGD(learning_rate=lr),\n",
        "              loss=MSE)\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A9YnL2gRpD8C"
      },
      "source": [
        "history1 = model.fit(X,y,epochs=200)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dYzB4ir2pIVi"
      },
      "source": [
        "plt.title('Loss Curve')\n",
        "plt.plot(history1.history['loss'])\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uyaFDLvYpJvh"
      },
      "source": [
        "model.predict([10.0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1Rp85p0kpMOb"
      },
      "source": [
        "## Part 3: Neural Networks"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nD7GqIVVpOXK"
      },
      "source": [
        "### 3.1 Multilayer Perceptron\n",
        "![image](https://www.researchgate.net/profile/Facundo_Bre/publication/321259051/figure/fig1/AS:614329250496529@1523478915726/Artificial-neural-network-architecture-ANN-i-h-1-h-2-h-n-o.png)\n",
        "\n",
        "As the name suggests, a multilayer perceptron (MLP) is a network of neurons or perceptrons arrange and connected horizontally and vertically. In this setup, neurons share knowledge along their respective layer and passes the activated values to the next layers to have a sense of \"deep\" learning. The concept of MLP gave rise to develop the new field of machine learning—Deep Learning, where we study about Artificial Neural Networks (ANN).\n",
        "\n",
        "An ANN consists of three parts:\n",
        "* Input layer\n",
        "* Hidden layer(s)\n",
        "* Output layer\n",
        "However, when counting the number of layers of a neural network we exclude the input layer since no learning is happening at the input layer or Layer 0 ($L0$)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-cj4NRRCpN7S"
      },
      "source": [
        "### Multilayer Perceptron\n",
        "model = tf.keras.Sequential([\n",
        "  tf.keras.layers.Dense(units=16,input_shape=[1]), #Hidden Layer\n",
        "  tf.keras.layers.Dense(units=1) #Output layer\n",
        "])\n",
        "\n",
        "lr=0.01\n",
        "model.compile(optimizer=SGD(learning_rate=lr),\n",
        "              loss=MSE)\n",
        "model.summary()\n",
        "history2=model.fit(X,y, epochs=200)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cfPf9y4ypK6N"
      },
      "source": [
        "plt.title('Loss Curve')\n",
        "plt.plot(history1.history['loss'], label='Single Neuron')\n",
        "plt.plot(history2.history['loss'], label='MLP')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aW1lmGjBpRja"
      },
      "source": [
        "model.predict([10.0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x6yHbONApWCa"
      },
      "source": [
        "### 3.2 Activation Functions\n",
        "\n",
        "![image](https://www.researchgate.net/profile/Junxi_Feng/publication/335845675/figure/fig3/AS:804124836765699@1568729709680/Commonly-used-activation-functions-a-Sigmoid-b-Tanh-c-ReLU-and-d-LReLU.ppm)\n",
        "\n",
        "Back in our discussion about the neuron, we know that an activaiton function is quite crucial in getting the right values. Different activation functions are used for different objectives of learning. One factor to consider in choosing an activation function is the behavior of outputs per layer or the expected output of the machine learning task. Simply, identifying whether you are classifying data or predicting data could help which activation function to use.\n",
        "\n",
        "For a deeper discussion and implementation check out:\n",
        "* [Activation functions in TensorFlow](https://www.tensorflow.org/api_docs/python/tf/keras/activations)\n",
        "* [Activation functions in Keras](https://keras.io/api/layers/activations/)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EaaRX3u_pSxz"
      },
      "source": [
        "from tensorflow.keras.layers import Activation\n",
        "from tensorflow.nn import sigmoid, tanh, softmax, relu, leaky_relu"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9YbMBaT6pYIU"
      },
      "source": [
        "inputs = tf.constant([\n",
        "                      [0.0,-1.2,2.4,32.0,-20.1]\n",
        "                      ])\n",
        "print(inputs)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iVgQCKsKpYRr"
      },
      "source": [
        "### Sigmoid\n",
        "sigmoid_layer = Activation(sigmoid)\n",
        "sigmoid_layer(inputs).numpy()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZOJiq7YIpYab"
      },
      "source": [
        "### Tanh\n",
        "tanh_layer = Activation(tanh)\n",
        "tanh_layer(inputs).numpy()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n61i5Y6OpYjM"
      },
      "source": [
        "### Softmax\n",
        "softmax_layer = Activation(softmax)\n",
        "softmax_layer(inputs).numpy()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2iTl5CsKpYri"
      },
      "source": [
        "### ReLU\n",
        "relu_layer = Activation(relu)\n",
        "relu_layer(inputs).numpy()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H7JEllMFp2Gk"
      },
      "source": [
        "### Leaky ReLU\n",
        "lrelu_layer = Activation(leaky_relu)\n",
        "lrelu_layer(inputs).numpy()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pDVPYkwXqBDS"
      },
      "source": [
        "## Laboratory Activity\n",
        "1. For the laboratory activity, obtain a dataset of your liking from a data source. Explain the purpose of the dataset and mention any publication if it is obtained from the source. Provide a needs statement and significance for the dataset.\n",
        "\n",
        "2. Identify an algorithm or method in performing a single or multiple variable classification using the Multilayer Perceptron alogrithm. \n",
        "\n",
        "3. You must re-create your Multi-Layer Perceptron using your own code in a separate Google Colab. However, you are required to observe the following:\n",
        "\n",
        ">* Enforce object-oriented programming by implementing at least two of the pillars of OOP in the entirety of the solution.\n",
        "* Dedicated functions for training, predicting, and evaluating the solution.\n",
        "* A DataFrame of the metrics of the solution\n",
        "* A visualization of the solution’s results."
      ]
    }
  ]
}